ğŸ§  Next Word Prediction using LSTM

An intelligent Next-Word Prediction Model built using LSTM (Long Short-Term Memory) networks in TensorFlow/Keras, with a Streamlit web interface for real-time text prediction. This project demonstrates NLP sequence modeling, text preprocessing, and model deployment in an interactive environment.

ğŸš€ Features

ğŸ”¤ Predicts the next word in a given text sequence using an LSTM-based language model.

âš™ï¸ Preprocessing pipeline using Keras Tokenizer and pad_sequences for sequence generation.

ğŸ’¾ Model serialized as next_word_lstm.h5 and Tokenizer saved via pickle for reproducible inference.

ğŸŒ Streamlit app for real-time text input and word prediction.

ğŸ§© Modular code structure for easy customization and deployment.

ğŸš€ Live Demo

ğŸ‘‰ Try it here: Next Word Predictor â€“ Streamlit App

(Replace with your actual Streamlit link)

ğŸ› ï¸ Tech Stack

Programming Language: Python

Frameworks & Libraries: TensorFlow, Keras, NumPy, Streamlit, Pickle

Model Type: LSTM (Recurrent Neural Network)

Interface: Streamlit Web App

ğŸ“ Project Structure
ğŸ“¦ next-word-prediction
â”œâ”€â”€ app.py                  # Streamlit app for UI and model inference
â”œâ”€â”€ experiments.ipynb       # Jupyter notebook for training and experiments
â”œâ”€â”€ next_word_lstm.h5       # Trained LSTM model
â”œâ”€â”€ tokenizer.pkl           # Saved Tokenizer for text preprocessing
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md               # Project documentation

âš™ï¸ Setup & Installation

Clone the repository

git clone https://github.com/<your-username>/next-word-prediction.git
cd next-word-prediction


Install dependencies

pip install -r requirements.txt


Run the Streamlit app

streamlit run app.py


Use the App

Enter a few words in the input box.

Click Predict to generate the most probable next word.

ğŸ“Š Model Overview

Architecture: LSTM with embedding + dense output layer

Input: Tokenized text sequences

Output: Predicted next word (via softmax)

Training: Performed on sample text data for demonstration (can be scaled for larger corpora)

ğŸ“ˆ Results

Demonstrates context-aware word prediction using recurrent sequence modeling.

Achieves smooth inference and accurate word suggestions for short text prompts.

ğŸ¤ Contributing

Contributions are welcome!
Feel free to fork this repository, open issues, or submit pull requests to improve the model or interface.


ğŸ‘¤ Author

Vaishnavi Newalkar

